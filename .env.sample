# Sample .env file for Medical Document Analyzer
# Copy this file to .env and adjust as needed

# LLM Backend Configuration
# Options: "ollama" or "llamacpp"
LLM_BACKEND=ollama

# Ollama Configuration
# URL for the Ollama server - use http://ollama:11434 for Docker setup
OLLAMA_HOST=http://localhost:11434

# LLM Models to use
# These are the model names as recognized by Ollama
OLLAMA_SUMMARY_MODEL=phi3
OLLAMA_ANALYZER_MODEL=llama3

# LlamaCpp Configuration (only needed if LLM_BACKEND=llamacpp)
LLAMACPP_THREADS=4
LLAMACPP_CONTEXT_SIZE=4096

# OCR Configuration
# Options: "tesseract" or "paddle"
OCR_ENGINE=tesseract
TESSERACT_CMD=tesseract

# File Retention Settings
FILE_RETENTION_DAYS=1

# Logging
LOG_LEVEL=INFO